/**
 * çœŸå®AIå¤„ç†å™¨ - åŸºäº Inception Labs API
 * ç”¨äºå¢å¼ºå’Œæ”¹è¿›Markdownæ–‡æ¡£å†…å®¹
 */

/**
 * AI è¯·æ±‚é…ç½®é€‰é¡¹
 */
interface AIRequestOptions {
  model?: string;
  max_tokens?: number;
  temperature?: number;
  timeout?: number;
  retries?: number;
  retryDelay?: number;
  structuredOutput?: boolean;
  outputSchema?: Record<string, unknown> | null;
  autoOptimize?: boolean;
}

/**
 * AI è¯·æ±‚å“åº”ç»“æ„
 */
interface AIResponse {
  content: string;
  raw: unknown;
  usage: Record<string, unknown>;
  structured?: unknown;
}

/**
 * å‘é€ AI è¯·æ±‚åˆ° Inception Labs API
 */
const aiRequest = async (messages: string | Array<unknown>, options: AIRequestOptions = {}): Promise<AIResponse> => {
  // é»˜è®¤é…ç½®
  const defaultOptions: AIRequestOptions = {
    model: "mercury-coder-small",
    max_tokens: 1000,
    temperature: 0,
    timeout: 30000,
    retries: 3,
    retryDelay: 1000,
    structuredOutput: false,
    outputSchema: null,
    autoOptimize: true,
  };

  const config = { ...defaultOptions, ...options };

  // è·å– API Key
  const apiKey = process.env.NEXT_PUBLIC_INCEPTION_API_KEY;
  if (!apiKey) {
    throw new Error("âŒ ç¼ºå°‘ NEXT_PUBLIC_INCEPTION_API_KEY ç¯å¢ƒå˜é‡");
  }

  // æ ¼å¼åŒ–æ¶ˆæ¯
  const formattedMessages = formatMessages(messages, config);

  // æ„å»ºè¯·æ±‚ä½“
  const requestBody = {
    model: config.model,
    messages: formattedMessages,
    max_tokens: config.max_tokens,
    temperature: config.temperature,
  };

  // å‘é€è¯·æ±‚ï¼ˆå¸¦é‡è¯•ï¼‰
  const response = await sendRequestWithRetry(requestBody, config, apiKey);

  return response;
};

/**
 * æ ¼å¼åŒ–æ¶ˆæ¯å†…å®¹
 */
const formatMessages = (messages: string | Array<unknown>, _config: AIRequestOptions): Array<Record<string, string>> => {
  let formattedMessages;

  if (typeof messages === "string") {
    formattedMessages = [{ role: "user", content: messages }];
  } else if (Array.isArray(messages)) {
    formattedMessages = messages.map((msg, index) => {
      if (typeof msg === "string") {
        return { role: "user", content: msg };
      }
      if (typeof msg === "object" && msg !== null && 'content' in msg && (msg as Record<string, unknown>).content) {
        const msgObj = msg as Record<string, string>;
        return {
          role: msgObj.role || "user",
          content: msgObj.content,
        };
      }
      throw new Error(`âŒ æ— æ•ˆçš„æ¶ˆæ¯æ ¼å¼ï¼Œç´¢å¼• ${index}: ${JSON.stringify(msg)}`);
    });
  } else {
    throw new Error("âŒ æ¶ˆæ¯æ ¼å¼é”™è¯¯ï¼Œåº”ä¸ºå­—ç¬¦ä¸²æˆ–æ•°ç»„");
  }

  return formattedMessages;
};

/**
 * å¸¦é‡è¯•æœºåˆ¶çš„è¯·æ±‚å‘é€
 */
const sendRequestWithRetry = async (requestBody: Record<string, unknown>, config: AIRequestOptions, apiKey: string): Promise<AIResponse> => {
  let lastError: Error = new Error('Unknown error');

  for (let attempt = 1; attempt <= (config.retries || 3); attempt++) {
    try {
      console.log(`ğŸš€ AI è¯·æ±‚å°è¯• ${attempt}/${config.retries}...`);

      const response = await fetch(
        "https://api.inceptionlabs.ai/v1/chat/completions",
        {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            Authorization: `Bearer ${apiKey}`,
          },
          body: JSON.stringify(requestBody),
          signal: AbortSignal.timeout(config.timeout || 30000),
        }
      );

      if (!response.ok) {
        const errorText = await response.text();
        
        // ç‰¹æ®Šå¤„ç†ä¸Šä¸‹æ–‡é•¿åº¦è¶…é™é”™è¯¯
        if (response.status === 400 && errorText.includes("context_length_exceeded")) {
          throw new Error(`âŒ è¯·æ±‚å†…å®¹è¿‡é•¿ï¼Œè¶…å‡ºæ¨¡å‹ä¸Šä¸‹æ–‡é™åˆ¶ (${response.status}): ${errorText}`);
        }
        
        throw new Error(`âŒ API è¯·æ±‚å¤±è´¥ (${response.status}): ${errorText}`);
      }

      const data = await response.json();

      if (!data.choices || !data.choices[0] || !data.choices[0].message) {
        throw new Error("âŒ API å“åº”æ ¼å¼é”™è¯¯");
      }

      console.log(`âœ… AI è¯·æ±‚æˆåŠŸ (å°è¯• ${attempt})`);

      return {
        content: data.choices[0].message.content,
        raw: data,
        usage: data.usage || {},
      };
    } catch (error: unknown) {
      lastError = error as Error;
      console.log(`âš ï¸ è¯·æ±‚å¤±è´¥ (å°è¯• ${attempt}): ${(error as Error).message}`);

      if (attempt < (config.retries || 3)) {
        console.log(`â³ ${config.retryDelay}ms åé‡è¯•...`);
        await new Promise((resolve) => setTimeout(resolve, config.retryDelay || 1000));
      }
    }
  }

  throw new Error(
    `âŒ AI è¯·æ±‚å¤±è´¥ï¼Œå·²é‡è¯• ${config.retries} æ¬¡: ${lastError.message}`
  );
};

/**
 * ä¾¿æ·å‡½æ•°ï¼šå‘é€ç®€å•æ–‡æœ¬è¯·æ±‚
 */
const aiChat = async (prompt: string, options: AIRequestOptions = {}): Promise<string> => {
  const response = await aiRequest(prompt, options);
  return response.content;
};

/**
 * çœŸå®AIå¤„ç†å™¨ç±»
 */
export class RealAIProcessor {
  private options: AIRequestOptions;

  constructor(options: AIRequestOptions = {}) {
    this.options = {
      model: "mercury-coder-small",
      max_tokens: 2000,
      temperature: 0.3,
      ...options
    };
  }

  /**
   * å¢å¼ºMarkdownæ–‡æ¡£
   * @param markdown - åŸå§‹Markdownæ–‡æœ¬
   * @returns å¢å¼ºåçš„Markdownæ–‡æœ¬
   */
  async enhance(markdown: string): Promise<string> {
    const prompt = `è¯·å¸®æˆ‘åœ¨ä»¥ä¸‹Markdownæ–‡æ¡£ä¸­æ™ºèƒ½æ’å…¥å†…é“¾åˆ° www.notta.aiã€‚

## é‡è¦è¦æ±‚ï¼š
- å®Œå…¨ä¿æŒåŸæ–‡çš„è¯­è¨€ã€è¯­è°ƒå’Œè¡¨è¾¾æ–¹å¼
- åªåœ¨åˆé€‚çš„åœ°æ–¹æ’å…¥é“¾æ¥ï¼Œä¸è¦ä¿®æ”¹ä»»ä½•å…¶ä»–å†…å®¹  
- ä¿æŒåŸæ–‡çš„ç»“æ„ã€æ ¼å¼å’Œæ‰€æœ‰ç»†èŠ‚ä¸å˜

## å†…é“¾æ’å…¥è§„åˆ™ï¼š
- åœ¨æåˆ° "Notta"ã€"è¯­éŸ³è½¬æ–‡å­—"ã€"å½•éŸ³è½¬å½•"ã€"éŸ³é¢‘è½¬æ–‡å­—"ã€"ä¼šè®®è®°å½•"ã€"å®æ—¶è½¬å½•"ã€"speech-to-text"ã€"transcribe"ã€"record audio" ç­‰ç›¸å…³æ¦‚å¿µæ—¶ï¼Œé€‚å½“æ’å…¥é“¾æ¥
- ä½¿ç”¨ [åŸæœ‰æ–‡æœ¬](https://www.notta.ai) çš„Markdowné“¾æ¥æ ¼å¼
- ä¿æŒåŸæœ‰çš„æ–‡æœ¬å†…å®¹ä¸å˜ï¼Œåªæ˜¯å°†ç›¸å…³è¯è¯­è½¬æ¢ä¸ºé“¾æ¥
- æ¯æ®µæœ€å¤šæ’å…¥1-2ä¸ªç›¸å…³é“¾æ¥ï¼Œé¿å…è¿‡åº¦é“¾æ¥
- ä¼˜å…ˆåœ¨å…³é”®è¯é¦–æ¬¡å‡ºç°æ—¶æ·»åŠ é“¾æ¥

## é“¾æ¥æ’å…¥ç¤ºä¾‹ï¼š
åŸæ–‡ï¼š"Notta may be useful"
ä¿®æ”¹ï¼š"[Notta](https://www.notta.ai) may be useful"

åŸæ–‡ï¼š"speech-to-text tools"
ä¿®æ”¹ï¼š"[speech-to-text](https://www.notta.ai) tools"

åŸæ–‡ï¼š"transcribe it in real-time"
ä¿®æ”¹ï¼š"[transcribe](https://www.notta.ai) it in real-time"

## ä¸¥æ ¼ç¦æ­¢ï¼š
- ä¸è¦æ”¹å˜åŸæ–‡çš„è¯­è¨€ï¼ˆè‹±æ–‡ä¿æŒè‹±æ–‡ï¼Œä¸­æ–‡ä¿æŒä¸­æ–‡ï¼‰
- ä¸è¦ä¿®æ”¹è¯­è°ƒæˆ–å†™ä½œé£æ ¼
- ä¸è¦æ·»åŠ æ–°çš„å†…å®¹æˆ–åˆ é™¤ç°æœ‰å†…å®¹
- ä¸è¦é‡å†™å¥å­æˆ–æ®µè½
- ä¸è¦æ”¹å˜æ ¼å¼ç»“æ„

è¯·ç›´æ¥è¿”å›æ’å…¥é“¾æ¥åçš„Markdownæ–‡æœ¬ï¼Œä¿æŒå…¶ä»–å†…å®¹å®Œå…¨ä¸å˜ï¼š

---

${markdown}`;

    try {
      const enhancedContent = await aiChat(prompt, this.options);
      return enhancedContent.trim();
    } catch (error) {
      console.error('AIå¤„ç†å¤±è´¥:', error);
      // å¦‚æœAIå¤„ç†å¤±è´¥ï¼Œè¿”å›å¸¦æœ‰ä¸€äº›åŸºæœ¬æ”¹è¿›çš„åŸæ–‡æ¡£
      return this.fallbackEnhancement(markdown);
    }
  }

  /**
   * å¤‡ç”¨å¢å¼ºæ–¹æ¡ˆ - å½“AIå¤„ç†å¤±è´¥æ—¶ä½¿ç”¨
   */
  private fallbackEnhancement(markdown: string): Promise<string> {
    return new Promise(resolve => {
      // æ¨¡æ‹ŸAIå¤„ç†å»¶è¿Ÿ
      setTimeout(() => {
        let enhanced = markdown;
        
        // åŸºæœ¬æ”¹è¿›
        enhanced = enhanced.replace(/# (.+)/g, '# $1 ğŸ“š');
        enhanced = enhanced.replace(/## (.+)/g, '## $1 ğŸ”§');
        
        // æ·»åŠ ä¸€äº›åŸºæœ¬çš„æ”¹è¿›
        if (enhanced.includes('API')) {
          enhanced += '\n\n## æœ€ä½³å®è·µ ğŸ’¡\n\n- ä½¿ç”¨é€‚å½“çš„é”™è¯¯å¤„ç†\n- å®ç°è¯·æ±‚é‡è¯•æœºåˆ¶\n- æ·»åŠ é€Ÿç‡é™åˆ¶ä¿æŠ¤\n- ä½¿ç”¨ç¼“å­˜æå‡æ€§èƒ½';
        }
        
        resolve(enhanced);
      }, 2000);
    });
  }
}

export { aiRequest, aiChat };
